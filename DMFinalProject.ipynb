{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv\n",
    "df = pd.read_csv('data/PHY_TRAIN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting target and predictors\n",
    "y = df['target']\n",
    "X = df.drop(['target', 'exampleid'],axis=1)\n",
    "feature_names = list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "              feat1         feat2         feat3         feat4         feat5  \\\ncount  50000.000000  50000.000000  50000.000000  50000.000000  50000.000000   \nmean       0.155606      0.084876     -0.050354     -0.000060      0.126569   \nstd        0.414875      0.295335      0.253748      0.392916      0.400694   \nmin        0.000000      0.000000     -1.000000     -1.000000      0.000000   \n25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n75%        0.000000      0.000000      0.000000      0.000000      0.000000   \nmax        2.639020      3.429590      0.999954      1.000000      2.719006   \n\n              feat6         feat7         feat8         feat9        feat10  \\\ncount  50000.000000  50000.000000  50000.000000  50000.000000  50000.000000   \nmean       0.049887     -0.038344      0.002860      0.848353      0.673485   \nstd        0.223713      0.214168      0.322077      0.453585      0.511087   \nmin        0.000000     -1.000000     -1.000000      0.000000      0.000000   \n25%        0.000000      0.000000      0.000000      0.522596      0.250301   \n50%        0.000000      0.000000      0.000000      0.787572      0.599672   \n75%        0.000000      0.000000      0.000000      1.105687      1.018601   \nmax        3.054644      0.999274      1.000000      6.699783      5.283748   \n\n       ...        feat69        feat70        feat71        feat72  \\\ncount  ...  50000.000000  50000.000000  50000.000000  50000.000000   \nmean   ...      0.008120      0.000478      0.003198      0.052807   \nstd    ...      0.769302      0.446978      0.381329      0.180710   \nmin    ...     -1.000000     -0.999998     -0.908001      0.000000   \n25%    ...     -1.000000     -0.000013     -0.001582      0.000000   \n50%    ...      0.000000      0.000000      0.000000      0.000000   \n75%    ...      1.000000      0.000015      0.003002      0.000000   \nmax    ...      1.000000      0.999999      0.907744      0.999953   \n\n             feat73        feat74        feat75        feat76        feat77  \\\ncount  50000.000000  50000.000000  50000.000000  50000.000000  50000.000000   \nmean       0.066944     -0.014101     -0.001460      0.094480      0.002843   \nstd        0.283114      0.176896      0.295939      0.315841      0.019081   \nmin        0.000000     -1.000000     -1.000000      0.000000      0.000000   \n25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n75%        0.000000      0.000000      0.000000      0.000000      0.000000   \nmax        3.429590      0.999869      1.000000      3.000000      0.385513   \n\n             feat78  \ncount  50000.000000  \nmean       0.066545  \nstd        0.223091  \nmin        0.000000  \n25%        0.000000  \n50%        0.000000  \n75%        0.000000  \nmax        1.000000  \n\n[8 rows x 78 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feat1</th>\n      <th>feat2</th>\n      <th>feat3</th>\n      <th>feat4</th>\n      <th>feat5</th>\n      <th>feat6</th>\n      <th>feat7</th>\n      <th>feat8</th>\n      <th>feat9</th>\n      <th>feat10</th>\n      <th>...</th>\n      <th>feat69</th>\n      <th>feat70</th>\n      <th>feat71</th>\n      <th>feat72</th>\n      <th>feat73</th>\n      <th>feat74</th>\n      <th>feat75</th>\n      <th>feat76</th>\n      <th>feat77</th>\n      <th>feat78</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>50000.000000</td>\n      <td>50000.000000</td>\n      <td>50000.000000</td>\n      <td>50000.000000</td>\n      <td>50000.000000</td>\n      <td>50000.000000</td>\n      <td>50000.000000</td>\n      <td>50000.000000</td>\n      <td>50000.000000</td>\n      <td>50000.000000</td>\n      <td>...</td>\n      <td>50000.000000</td>\n      <td>50000.000000</td>\n      <td>50000.000000</td>\n      <td>50000.000000</td>\n      <td>50000.000000</td>\n      <td>50000.000000</td>\n      <td>50000.000000</td>\n      <td>50000.000000</td>\n      <td>50000.000000</td>\n      <td>50000.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.155606</td>\n      <td>0.084876</td>\n      <td>-0.050354</td>\n      <td>-0.000060</td>\n      <td>0.126569</td>\n      <td>0.049887</td>\n      <td>-0.038344</td>\n      <td>0.002860</td>\n      <td>0.848353</td>\n      <td>0.673485</td>\n      <td>...</td>\n      <td>0.008120</td>\n      <td>0.000478</td>\n      <td>0.003198</td>\n      <td>0.052807</td>\n      <td>0.066944</td>\n      <td>-0.014101</td>\n      <td>-0.001460</td>\n      <td>0.094480</td>\n      <td>0.002843</td>\n      <td>0.066545</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.414875</td>\n      <td>0.295335</td>\n      <td>0.253748</td>\n      <td>0.392916</td>\n      <td>0.400694</td>\n      <td>0.223713</td>\n      <td>0.214168</td>\n      <td>0.322077</td>\n      <td>0.453585</td>\n      <td>0.511087</td>\n      <td>...</td>\n      <td>0.769302</td>\n      <td>0.446978</td>\n      <td>0.381329</td>\n      <td>0.180710</td>\n      <td>0.283114</td>\n      <td>0.176896</td>\n      <td>0.295939</td>\n      <td>0.315841</td>\n      <td>0.019081</td>\n      <td>0.223091</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>-1.000000</td>\n      <td>-0.999998</td>\n      <td>-0.908001</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.522596</td>\n      <td>0.250301</td>\n      <td>...</td>\n      <td>-1.000000</td>\n      <td>-0.000013</td>\n      <td>-0.001582</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.787572</td>\n      <td>0.599672</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.105687</td>\n      <td>1.018601</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>0.000015</td>\n      <td>0.003002</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2.639020</td>\n      <td>3.429590</td>\n      <td>0.999954</td>\n      <td>1.000000</td>\n      <td>2.719006</td>\n      <td>3.054644</td>\n      <td>0.999274</td>\n      <td>1.000000</td>\n      <td>6.699783</td>\n      <td>5.283748</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>0.999999</td>\n      <td>0.907744</td>\n      <td>0.999953</td>\n      <td>3.429590</td>\n      <td>0.999869</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>0.385513</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows Ã— 78 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#STEP 1: Data Exploration\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "count    50000.000000\nmean         0.497220\nstd          0.499997\nmin          0.000000\n25%          0.000000\n50%          0.000000\n75%          1.000000\nmax          1.000000\nName: target, dtype: float64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data exploration for target variables\n",
    "y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0    25139\n1    24861\nName: target, dtype: int64"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()\n",
    "\n",
    "#sns.countplot(x = y, data=y)\n",
    "#plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0        0\n1        0\n2        1\n3        0\n4        0\n        ..\n49995    0\n49996    1\n49997    1\n49998    1\n49999    0\nName: target, Length: 50000, dtype: int64"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1, 1, 1, ..., 0, 0, 1],\n       [0, 0, 0, ..., 1, 1, 1],\n       [0, 0, 0, ..., 0, 0, 1],\n       ...,\n       [0, 0, 0, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0]])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#STEP 2: Missing value indicator\n",
    "from sklearn.impute import MissingIndicator\n",
    "#True indicates Missing Value, False indicates no missing value\n",
    "\n",
    "#indicator = MissingIndicator(features='all')\n",
    "indicator = MissingIndicator(features='missing-only')\n",
    "missing = indicator.fit_transform(X)\n",
    "#converts boolean to integers\n",
    "missing.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 3: Replace missing values with mean\n",
    "from sklearn.impute import SimpleImputer\n",
    "mean_imputer = SimpleImputer()\n",
    "mean_imputer = mean_imputer.fit(X)\n",
    "df1 = pd.DataFrame(mean_imputer.transform(X),columns = feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    7.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to run the model 0.0\n",
      "Time to run 5-Folds 7.656734466552734\n",
      "Mean accuracy through 5-folds 0.6976199999999999\n"
     ]
    }
   ],
   "source": [
    "#STEP 4 Ignored because we have not taken a data prep course\n",
    "#STEP 5 Modeling\n",
    "# n_jobs at -1 WILL USE UP A LOT OF MEMORY for your computer.\n",
    "# It may cause the computer to become VERY SLOW at doing anything else.\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from time import time\n",
    "t0 = time()\n",
    "#Logistic Regression w/o Interaction Terms\n",
    "logitModel = LogisticRegression(n_jobs=-1)\n",
    "t1 = time()\n",
    "logitValues = cross_val_score(logitModel, df1, y=y, n_jobs=-1, verbose=1, scoring=\"accuracy\")\n",
    "t2 = time()\n",
    "logitMean = logitValues.mean()\n",
    "print(\"Time to run the model\", t1 - t0)\n",
    "print(\"Time to run 5-Folds\", t2 - t1)\n",
    "print(\"Mean accuracy through 5-folds\", logitMean)\n",
    "#******Might want to try Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.6982"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logitModel.fit(df1,y)\n",
    "baseline = logitModel.score(df1,y)\n",
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 79 features per sample; expecting 78",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-13-2984559690c0>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      7\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mfeature_A\u001B[0m \u001B[1;33m>\u001B[0m \u001B[0mfeature_B\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m             \u001B[0mdf1\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'interaction'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdf1\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mfeature_A\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mdf1\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mfeature_B\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 9\u001B[1;33m             \u001B[0mscore\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlogitModel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mscore\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdf1\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     10\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mscore\u001B[0m \u001B[1;33m>\u001B[0m \u001B[0mbaseline\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m                 \u001B[0minteractions\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfeature_A\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfeature_B\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mround\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mscore\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m8\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001B[0m in \u001B[0;36mscore\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    367\u001B[0m         \"\"\"\n\u001B[0;32m    368\u001B[0m         \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0mmetrics\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0maccuracy_score\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 369\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0maccuracy_score\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msample_weight\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    370\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    371\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001B[0m in \u001B[0;36mpredict\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    291\u001B[0m             \u001B[0mPredicted\u001B[0m \u001B[1;32mclass\u001B[0m \u001B[0mlabel\u001B[0m \u001B[0mper\u001B[0m \u001B[0msample\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    292\u001B[0m         \"\"\"\n\u001B[1;32m--> 293\u001B[1;33m         \u001B[0mscores\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdecision_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    294\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mscores\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    295\u001B[0m             \u001B[0mindices\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mscores\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mint\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001B[0m in \u001B[0;36mdecision_function\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    271\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[0mn_features\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    272\u001B[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001B[1;32m--> 273\u001B[1;33m                              % (X.shape[1], n_features))\n\u001B[0m\u001B[0;32m    274\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    275\u001B[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001B[1;31mValueError\u001B[0m: X has 79 features per sample; expecting 78"
     ]
    }
   ],
   "source": [
    "# Logistic regression with at least three two-way interactions\n",
    "# this part might not work for multiple features n\n",
    "score = 0\n",
    "interactions = list()\n",
    "for feature_A in feature_names:\n",
    "    for feature_B in feature_names:\n",
    "        if feature_A > feature_B:\n",
    "            df1['interaction'] = df1[feature_A] * df1[feature_B]\n",
    "            score = logitModel.score(df1,y)\n",
    "            if score > baseline:\n",
    "                interactions.append((feature_A, feature_B, round(score,8)))\n",
    "#print(df1)\n",
    "print('Baseline R2: %.3f' % baseline)\n",
    "print('Top 10 interactions: %s' % sorted(interactions ,key = lambda x:x[2], reverse=True)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------Random Forest----------\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# sorted(sklearn.metrics.SCORERS.keys())\n",
    "\n",
    "# Gini\n",
    "t0 = time()\n",
    "rfGini = RandomForestClassifier(criterion=\"gini\", n_estimators = 100, random_state = 42, n_jobs=-1, verbose=1)\n",
    "t1 = time()\n",
    "dtGiniValues = cross_val_score(rfGini, df1, y=y, n_jobs=-1, verbose=1, scoring=\"accuracy\")\n",
    "t2 = time()\n",
    "dtGiniMean = dtGiniValues.mean()\n",
    "print(\"Time to run the model\", t1 - t0)\n",
    "print(\"Time to run 5-Folds\", t2 - t1)\n",
    "print(\"Mean accuracy through 5-folds\", dtGiniMean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Entropy\n",
    "t0 = time()\n",
    "rfEntropy = RandomForestClassifier(criterion=\"entropy\", n_estimators = 100, random_state = 42, n_jobs=-1, verbose=1)\n",
    "t1 = time()\n",
    "dtEntropyValues = cross_val_score(rfEntropy, df1, y=y, n_jobs=-1, verbose=1, scoring=\"accuracy\")\n",
    "t2 = time()\n",
    "dtEntropyMean = dtEntropyValues.mean()\n",
    "print(\"Time to run the model\", t1 - t0)\n",
    "print(\"Time to run 5-Folds\", t2 - t1)\n",
    "print(\"Mean accuracy through 5-folds\", dtEntropyMean)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Gradient Boosting Classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "t0 = time()\n",
    "gb_clf = GradientBoostingClassifier()\n",
    "t1 = time()\n",
    "gbclfScores = cross_val_score(gb_clf, df1, y=y, n_jobs=-1, verbose=1, scoring=\"accuracy\")\n",
    "t2 = time()\n",
    "gbclfMean = gbclfScores.mean()\n",
    "print(\"Time to run the model\", t1 - t0)\n",
    "print(\"Time to run 5-Folds\", t2 - t1)\n",
    "print(\"Mean accuracy through 5-folds\", gbclfMean)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 6: Comparisons of fitted models using c-statistics, i.e., AUC of the ROC curve"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
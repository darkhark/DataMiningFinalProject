{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv\n",
    "df = pd.read_csv('data/PHY_TRAIN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting target and predictors\n",
    "y = df['target']\n",
    "X = df.drop(['target', 'exampleid'],axis=1)\n",
    "feature_names = list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "              feat1         feat2         feat3         feat4         feat5  \\\ncount  50000.000000  50000.000000  50000.000000  50000.000000  50000.000000   \nmean       0.155606      0.084876     -0.050354     -0.000060      0.126569   \nstd        0.414875      0.295335      0.253748      0.392916      0.400694   \nmin        0.000000      0.000000     -1.000000     -1.000000      0.000000   \n25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n75%        0.000000      0.000000      0.000000      0.000000      0.000000   \nmax        2.639020      3.429590      0.999954      1.000000      2.719006   \n\n              feat6         feat7         feat8         feat9        feat10  \\\ncount  50000.000000  50000.000000  50000.000000  50000.000000  50000.000000   \nmean       0.049887     -0.038344      0.002860      0.848353      0.673485   \nstd        0.223713      0.214168      0.322077      0.453585      0.511087   \nmin        0.000000     -1.000000     -1.000000      0.000000      0.000000   \n25%        0.000000      0.000000      0.000000      0.522596      0.250301   \n50%        0.000000      0.000000      0.000000      0.787572      0.599672   \n75%        0.000000      0.000000      0.000000      1.105687      1.018601   \nmax        3.054644      0.999274      1.000000      6.699783      5.283748   \n\n       ...        feat69        feat70        feat71        feat72  \\\ncount  ...  50000.000000  50000.000000  50000.000000  50000.000000   \nmean   ...      0.008120      0.000478      0.003198      0.052807   \nstd    ...      0.769302      0.446978      0.381329      0.180710   \nmin    ...     -1.000000     -0.999998     -0.908001      0.000000   \n25%    ...     -1.000000     -0.000013     -0.001582      0.000000   \n50%    ...      0.000000      0.000000      0.000000      0.000000   \n75%    ...      1.000000      0.000015      0.003002      0.000000   \nmax    ...      1.000000      0.999999      0.907744      0.999953   \n\n             feat73        feat74        feat75        feat76        feat77  \\\ncount  50000.000000  50000.000000  50000.000000  50000.000000  50000.000000   \nmean       0.066944     -0.014101     -0.001460      0.094480      0.002843   \nstd        0.283114      0.176896      0.295939      0.315841      0.019081   \nmin        0.000000     -1.000000     -1.000000      0.000000      0.000000   \n25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n75%        0.000000      0.000000      0.000000      0.000000      0.000000   \nmax        3.429590      0.999869      1.000000      3.000000      0.385513   \n\n             feat78  \ncount  50000.000000  \nmean       0.066545  \nstd        0.223091  \nmin        0.000000  \n25%        0.000000  \n50%        0.000000  \n75%        0.000000  \nmax        1.000000  \n\n[8 rows x 78 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feat1</th>\n      <th>feat2</th>\n      <th>feat3</th>\n      <th>feat4</th>\n      <th>feat5</th>\n      <th>feat6</th>\n      <th>feat7</th>\n      <th>feat8</th>\n      <th>feat9</th>\n      <th>feat10</th>\n      <th>...</th>\n      <th>feat69</th>\n      <th>feat70</th>\n      <th>feat71</th>\n      <th>feat72</th>\n      <th>feat73</th>\n      <th>feat74</th>\n      <th>feat75</th>\n      <th>feat76</th>\n      <th>feat77</th>\n      <th>feat78</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>50000.000000</td>\n      <td>50000.000000</td>\n      <td>50000.000000</td>\n      <td>50000.000000</td>\n      <td>50000.000000</td>\n      <td>50000.000000</td>\n      <td>50000.000000</td>\n      <td>50000.000000</td>\n      <td>50000.000000</td>\n      <td>50000.000000</td>\n      <td>...</td>\n      <td>50000.000000</td>\n      <td>50000.000000</td>\n      <td>50000.000000</td>\n      <td>50000.000000</td>\n      <td>50000.000000</td>\n      <td>50000.000000</td>\n      <td>50000.000000</td>\n      <td>50000.000000</td>\n      <td>50000.000000</td>\n      <td>50000.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.155606</td>\n      <td>0.084876</td>\n      <td>-0.050354</td>\n      <td>-0.000060</td>\n      <td>0.126569</td>\n      <td>0.049887</td>\n      <td>-0.038344</td>\n      <td>0.002860</td>\n      <td>0.848353</td>\n      <td>0.673485</td>\n      <td>...</td>\n      <td>0.008120</td>\n      <td>0.000478</td>\n      <td>0.003198</td>\n      <td>0.052807</td>\n      <td>0.066944</td>\n      <td>-0.014101</td>\n      <td>-0.001460</td>\n      <td>0.094480</td>\n      <td>0.002843</td>\n      <td>0.066545</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.414875</td>\n      <td>0.295335</td>\n      <td>0.253748</td>\n      <td>0.392916</td>\n      <td>0.400694</td>\n      <td>0.223713</td>\n      <td>0.214168</td>\n      <td>0.322077</td>\n      <td>0.453585</td>\n      <td>0.511087</td>\n      <td>...</td>\n      <td>0.769302</td>\n      <td>0.446978</td>\n      <td>0.381329</td>\n      <td>0.180710</td>\n      <td>0.283114</td>\n      <td>0.176896</td>\n      <td>0.295939</td>\n      <td>0.315841</td>\n      <td>0.019081</td>\n      <td>0.223091</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>-1.000000</td>\n      <td>-0.999998</td>\n      <td>-0.908001</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.522596</td>\n      <td>0.250301</td>\n      <td>...</td>\n      <td>-1.000000</td>\n      <td>-0.000013</td>\n      <td>-0.001582</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.787572</td>\n      <td>0.599672</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.105687</td>\n      <td>1.018601</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>0.000015</td>\n      <td>0.003002</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2.639020</td>\n      <td>3.429590</td>\n      <td>0.999954</td>\n      <td>1.000000</td>\n      <td>2.719006</td>\n      <td>3.054644</td>\n      <td>0.999274</td>\n      <td>1.000000</td>\n      <td>6.699783</td>\n      <td>5.283748</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>0.999999</td>\n      <td>0.907744</td>\n      <td>0.999953</td>\n      <td>3.429590</td>\n      <td>0.999869</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>0.385513</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows Ã— 78 columns</p>\n</div>"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 1: Data Exploration\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "count    50000.000000\nmean         0.497220\nstd          0.499997\nmin          0.000000\n25%          0.000000\n50%          0.000000\n75%          1.000000\nmax          1.000000\nName: target, dtype: float64"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data exploration for target variables\n",
    "y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0    25139\n1    24861\nName: target, dtype: int64"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()\n",
    "\n",
    "# sns.countplot(x = y, data=y)\n",
    "# plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0        0\n1        0\n2        1\n3        0\n4        0\n        ..\n49995    0\n49996    1\n49997    1\n49998    1\n49999    0\nName: target, Length: 50000, dtype: int64"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1, 1, 1, ..., 0, 0, 1],\n       [0, 0, 0, ..., 1, 1, 1],\n       [0, 0, 0, ..., 0, 0, 1],\n       ...,\n       [0, 0, 0, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0]])"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 2: Missing value indicator\n",
    "from sklearn.impute import MissingIndicator\n",
    "# True indicates Missing Value, False indicates no missing value\n",
    "\n",
    "# indicator = MissingIndicator(features='all')\n",
    "indicator = MissingIndicator(features='missing-only')\n",
    "missing = indicator.fit_transform(X)\n",
    "# converts boolean to integers\n",
    "missing.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: Replace missing values with mean\n",
    "from sklearn.impute import SimpleImputer\n",
    "simple_imputer = SimpleImputer()\n",
    "mean_imputer = simple_imputer.fit(X)\n",
    "df1 = pd.DataFrame(mean_imputer.transform(X), columns = feature_names)\n",
    "\n",
    "# Replace missing values with KNN\n",
    "# causes my kernel to die\n",
    "# from sklearn.impute import KNNImputer\n",
    "# imputer = KNNImputer(n_neighbors=2)\n",
    "# imputer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4 Transformation of selected variables are recommended if you use logistic regression, however,\n",
    "# for students without data preparation class can ignore this part\n",
    "\n",
    "# Normalizing coefficients (Accuracy decreases)\n",
    "column_maxes = df1.max()\n",
    "column_mins = df1.min()\n",
    "df_min = column_mins.min()\n",
    "df_max = column_maxes.max()\n",
    "normalized_df = (df1 - df_min) / (df_max - df_min)\n",
    "df1 = normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to run the model 0.0\n",
      "Time to run 5-Folds 3.371889352798462\n",
      "Mean accuracy through 5-folds 0.50136\n"
     ]
    }
   ],
   "source": [
    "# STEP 5 Modeling\n",
    "# n_jobs at -1 WILL USE UP A LOT OF MEMORY for your computer.\n",
    "# It may cause the computer to become VERY SLOW at doing anything else.\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from time import time\n",
    "t0 = time()\n",
    "# Logistic Regression w/o Interaction Terms\n",
    "logitModel = LogisticRegression(penalty='l2', n_jobs=-1)\n",
    "t1 = time()\n",
    "logitValues = cross_val_score(logitModel, df1, y=y, n_jobs=-1, verbose=1, scoring=\"accuracy\")\n",
    "t2 = time()\n",
    "logitMean = logitValues.mean()\n",
    "print(\"Time to run the model\", t1 - t0)\n",
    "print(\"Time to run 5-Folds\", t2 - t1)\n",
    "print(\"Mean accuracy through 5-folds\", logitMean)\n",
    "#******Might want to try Recursive Feature Elimination"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 10\n",
      "Selected Features: [False False False False False False False False False False False  True\n",
      "  True False False False False False False  True False False False False\n",
      " False False False False False False  True False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False  True False False False False\n",
      " False False  True False False  True False False  True  True  True False\n",
      " False False False False False False]\n",
      "Feature Ranking: [16 60 42  2 49 55 29  4 33 19 12  1  1  7 14 15 25 44 31  1 13 36 17 59\n",
      " 18 20 56 54 65 50  1  5  8 47 40 30 58 39 11 45 53 38 22 21 23 26 64 66\n",
      " 67 68 69  9 61 48 63  1  3  6 52 24 27 35  1 62 28  1 32 57  1  1  1 34\n",
      " 41 37 10 46 51 43]\n"
     ]
    }
   ],
   "source": [
    "#Recursive Feature Elimination\n",
    "from sklearn.feature_selection import RFE\n",
    "rfe = RFE(logitModel, 10)\n",
    "fit = rfe.fit(df1, y)\n",
    "print(\"Num Features: %d\" % fit.n_features_)\n",
    "print(\"Selected Features: %s\" % fit.support_)\n",
    "print(\"Feature Ranking: %s\" % fit.ranking_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "RFECV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n      estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                   fit_intercept=True, intercept_scaling=1,\n                                   l1_ratio=None, max_iter=100,\n                                   multi_class='auto', n_jobs=-1, penalty='l2',\n                                   random_state=None, solver='lbfgs',\n                                   tol=0.0001, verbose=0, warm_start=False),\n      min_features_to_select=1, n_jobs=None, scoring='accuracy', step=1,\n      verbose=0)"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "#rfc = RandomForestClassifier(random_state=101)\n",
    "rfc = LogisticRegression(penalty='l2',n_jobs=-1)\n",
    "rfecv = RFECV(estimator=rfc, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(df1, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "# What?\n",
    "clf = LogisticRegression(penalty=\"l2\")\n",
    "clf.fit(df1,y)\n",
    "thetaLasso=clf.coef_\n",
    "#print(\"The regularized theta using lasso regression:\\n\",thetaLasso.reshape(78,1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.5037"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logitModel.fit(df1,y)\n",
    "baseline = logitModel.score(df1,y)\n",
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression with at least three two-way interactions\n",
    "# this part might not work for multiple features n\n",
    "\n",
    "score = 0\n",
    "tempDF = df1.copy()\n",
    "interactions = list()\n",
    "feature_indexes = list(range(len(X.columns)))\n",
    "newColumns = {}\n",
    "for index in feature_indexes:\n",
    "   tempDF.rename(columns={X.columns[index]:str(index)}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "\t 1\n",
      "\t 2\n",
      "\t 3\n",
      "\t 4\n",
      "\t 5\n",
      "\t 6\n",
      "\t 7\n",
      "\t 8\n",
      "\t 9\n",
      "\t 10\n",
      "\t 11\n",
      "\t 12\n",
      "\t 13\n",
      "\t 14\n",
      "\t 15\n",
      "\t 16\n",
      "\t 17\n",
      "\t 18\n",
      "\t 19\n",
      "\t 20\n",
      "\t 21\n",
      "\t 22\n",
      "\t 23\n",
      "\t 24\n",
      "\t 25\n",
      "\t 26\n",
      "\t 27\n",
      "\t 28\n",
      "\t 29\n",
      "\t 30\n",
      "\t 31\n",
      "\t 32\n",
      "\t 33\n",
      "\t 34\n",
      "\t 35\n",
      "\t 36\n",
      "\t 37\n",
      "\t 38\n",
      "\t 39\n",
      "\t 40\n",
      "\t 41\n",
      "\t 42\n",
      "\t 43\n",
      "\t 44\n",
      "\t 45\n",
      "\t 46\n",
      "\t 47\n",
      "\t 48\n",
      "\t 49\n",
      "\t 50\n",
      "\t 51\n",
      "\t 52\n",
      "\t 53\n",
      "\t 54\n",
      "\t 55\n",
      "\t 56\n",
      "\t 57\n",
      "\t 58\n",
      "\t 59\n",
      "\t 60\n",
      "\t 61\n",
      "\t 62\n",
      "\t 63\n",
      "\t 64\n",
      "\t 65\n",
      "\t 66\n",
      "\t 67\n",
      "\t 68\n",
      "\t 69\n",
      "\t 70\n",
      "\t 71\n",
      "\t 72\n",
      "\t 73\n",
      "\t 74\n",
      "\t 75\n",
      "\t 76\n",
      "\t 77\n",
      "1\n",
      "\t 2\n",
      "\t 3\n",
      "\t 4\n",
      "\t 5\n",
      "\t 6\n",
      "\t 7\n",
      "\t 8\n",
      "\t 9\n",
      "\t 10\n",
      "\t 11\n",
      "\t 12\n",
      "\t 13\n",
      "\t 14\n",
      "\t 15\n",
      "\t 16\n",
      "\t 17\n",
      "\t 18\n",
      "\t 19\n",
      "\t 20\n",
      "\t 21\n",
      "\t 22\n",
      "\t 23\n",
      "\t 24\n",
      "\t 25\n",
      "\t 26\n",
      "\t 27\n",
      "\t 28\n",
      "\t 29\n",
      "\t 30\n",
      "\t 31\n",
      "\t 32\n",
      "\t 33\n",
      "\t 34\n",
      "\t 35\n",
      "\t 36\n",
      "\t 37\n",
      "\t 38\n",
      "\t 39\n",
      "\t 40\n",
      "\t 41\n",
      "\t 42\n",
      "\t 43\n",
      "\t 44\n",
      "\t 45\n",
      "\t 46\n",
      "\t 47\n",
      "\t 48\n",
      "\t 49\n",
      "\t 50\n",
      "\t 51\n",
      "\t 52\n",
      "\t 53\n",
      "\t 54\n",
      "\t 55\n",
      "\t 56\n",
      "\t 57\n",
      "\t 58\n",
      "\t 59\n",
      "\t 60\n",
      "\t 61\n",
      "\t 62\n",
      "\t 63\n",
      "\t 64\n",
      "\t 65\n",
      "\t 66\n",
      "\t 67\n",
      "\t 68\n",
      "\t 69\n",
      "\t 70\n",
      "\t 71\n",
      "\t 72\n",
      "\t 73\n",
      "\t 74\n",
      "\t 75\n",
      "\t 76\n",
      "\t 77\n",
      "2\n",
      "\t 3\n",
      "\t 4\n",
      "\t 5\n",
      "\t 6\n",
      "\t 7\n",
      "\t 8\n",
      "\t 9\n",
      "\t 10\n",
      "\t 11\n",
      "\t 12\n",
      "\t 13\n",
      "\t 14\n",
      "\t 15\n",
      "\t 16\n",
      "\t 17\n",
      "\t 18\n",
      "\t 19\n",
      "\t 20\n",
      "\t 21\n",
      "\t 22\n",
      "\t 23\n",
      "\t 24\n",
      "\t 25\n",
      "\t 26\n",
      "\t 27\n",
      "\t 28\n",
      "\t 29\n",
      "\t 30\n",
      "\t 31\n",
      "\t 32\n",
      "\t 33\n",
      "\t 34\n",
      "\t 35\n",
      "\t 36\n",
      "\t 37\n",
      "\t 38\n",
      "\t 39\n",
      "\t 40\n",
      "\t 41\n",
      "\t 42\n",
      "\t 43\n",
      "\t 44\n",
      "\t 45\n",
      "\t 46\n",
      "\t 47\n",
      "\t 48\n",
      "\t 49\n",
      "\t 50\n",
      "\t 51\n",
      "\t 52\n",
      "\t 53\n",
      "\t 54\n",
      "\t 55\n",
      "\t 56\n",
      "\t 57\n",
      "\t 58\n",
      "\t 59\n",
      "\t 60\n",
      "\t 61\n",
      "\t 62\n",
      "\t 63\n",
      "\t 64\n",
      "\t 65\n",
      "\t 66\n",
      "\t 67\n",
      "\t 68\n",
      "\t 69\n",
      "\t 70\n",
      "\t 71\n",
      "\t 72\n",
      "\t 73\n",
      "\t 74\n",
      "\t 75\n",
      "\t 76\n",
      "\t 77\n",
      "3\n",
      "\t 4\n",
      "\t 5\n",
      "\t 6\n",
      "\t 7\n",
      "\t 8\n",
      "\t 9\n",
      "\t 10\n",
      "\t 11\n",
      "\t 12\n",
      "\t 13\n",
      "\t 14\n",
      "\t 15\n",
      "\t 16\n",
      "\t 17\n",
      "\t 18\n",
      "\t 19\n",
      "\t 20\n",
      "\t 21\n",
      "\t 22\n",
      "\t 23\n",
      "\t 24\n",
      "\t 25\n",
      "\t 26\n",
      "\t 27\n",
      "\t 28\n",
      "\t 29\n",
      "\t 30\n",
      "\t 31\n",
      "\t 32\n",
      "\t 33\n",
      "\t 34\n",
      "\t 35\n",
      "\t 36\n",
      "\t 37\n",
      "\t 38\n",
      "\t 39\n",
      "\t 40\n",
      "\t 41\n",
      "\t 42\n",
      "\t 43\n",
      "\t 44\n",
      "\t 45\n",
      "\t 46\n",
      "\t 47\n",
      "\t 48\n",
      "\t 49\n",
      "\t 50\n",
      "\t 51\n",
      "\t 52\n",
      "\t 53\n",
      "\t 54\n",
      "\t 55\n",
      "\t 56\n",
      "\t 57\n",
      "\t 58\n",
      "\t 59\n",
      "\t 60\n",
      "\t 61\n",
      "\t 62\n",
      "\t 63\n",
      "\t 64\n",
      "\t 65\n",
      "\t 66\n",
      "\t 67\n",
      "\t 68\n",
      "\t 69\n",
      "\t 70\n",
      "\t 71\n",
      "\t 72\n",
      "\t 73\n",
      "\t 74\n",
      "\t 75\n",
      "\t 76\n",
      "\t 77\n",
      "4\n",
      "\t 5\n",
      "\t 6\n",
      "\t 7\n",
      "\t 8\n",
      "\t 9\n",
      "\t 10\n",
      "\t 11\n",
      "\t 12\n",
      "\t 13\n",
      "\t 14\n",
      "\t 15\n",
      "\t 16\n",
      "\t 17\n",
      "\t 18\n",
      "\t 19\n",
      "\t 20\n",
      "\t 21\n",
      "\t 22\n",
      "\t 23\n",
      "\t 24\n",
      "\t 25\n",
      "\t 26\n",
      "\t 27\n",
      "\t 28\n",
      "\t 29\n",
      "\t 30\n",
      "\t 31\n",
      "\t 32\n",
      "\t 33\n",
      "\t 34\n",
      "\t 35\n",
      "\t 36\n",
      "\t 37\n",
      "\t 38\n",
      "\t 39\n",
      "\t 40\n",
      "\t 41\n",
      "\t 42\n",
      "\t 43\n",
      "\t 44\n",
      "\t 45\n",
      "\t 46\n",
      "\t 47\n",
      "\t 48\n",
      "\t 49\n",
      "\t 50\n",
      "\t 51\n",
      "\t 52\n",
      "\t 53\n",
      "\t 54\n",
      "\t 55\n",
      "\t 56\n",
      "\t 57\n",
      "\t 58\n",
      "\t 59\n",
      "\t 60\n",
      "\t 61\n",
      "\t 62\n",
      "\t 63\n",
      "\t 64\n",
      "\t 65\n",
      "\t 66\n",
      "\t 67\n",
      "\t 68\n",
      "\t 69\n",
      "\t 70\n",
      "\t 71\n",
      "\t 72\n",
      "\t 73\n",
      "\t 74\n",
      "\t 75\n",
      "\t 76\n",
      "\t 77\n",
      "5\n",
      "\t 6\n",
      "\t 7\n",
      "\t 8\n",
      "\t 9\n",
      "\t 10\n",
      "\t 11\n",
      "\t 12\n",
      "\t 13\n",
      "\t 14\n",
      "\t 15\n",
      "\t 16\n",
      "\t 17\n",
      "\t 18\n",
      "\t 19\n",
      "\t 20\n",
      "\t 21\n",
      "\t 22\n",
      "\t 23\n",
      "\t 24\n",
      "\t 25\n",
      "\t 26\n",
      "\t 27\n",
      "\t 28\n",
      "\t 29\n",
      "\t 30\n",
      "\t 31\n",
      "\t 32\n",
      "\t 33\n",
      "\t 34\n",
      "\t 35\n",
      "\t 36\n",
      "\t 37\n",
      "\t 38\n",
      "\t 39\n",
      "\t 40\n",
      "\t 41\n",
      "\t 42\n",
      "\t 43\n",
      "\t 44\n",
      "\t 45\n",
      "\t 46\n",
      "\t 47\n",
      "\t 48\n",
      "\t 49\n",
      "\t 50\n",
      "\t 51\n",
      "\t 52\n",
      "\t 53\n",
      "\t 54\n",
      "\t 55\n",
      "\t 56\n",
      "\t 57\n",
      "\t 58\n",
      "\t 59\n",
      "\t 60\n",
      "\t 61\n",
      "\t 62\n",
      "\t 63\n",
      "\t 64\n",
      "\t 65\n",
      "\t 66\n",
      "\t 67\n",
      "\t 68\n",
      "\t 69\n",
      "\t 70\n",
      "\t 71\n",
      "\t 72\n",
      "\t 73\n",
      "\t 74\n",
      "\t 75\n",
      "\t 76\n",
      "\t 77\n",
      "6\n",
      "\t 7\n",
      "\t 8\n",
      "\t 9\n",
      "\t 10\n",
      "\t 11\n",
      "\t 12\n",
      "\t 13\n",
      "\t 14\n",
      "\t 15\n",
      "\t 16\n",
      "\t 17\n",
      "\t 18\n",
      "\t 19\n",
      "\t 20\n",
      "\t 21\n",
      "\t 22\n",
      "\t 23\n",
      "\t 24\n",
      "\t 25\n",
      "\t 26\n",
      "\t 27\n",
      "\t 28\n",
      "\t 29\n",
      "\t 30\n",
      "\t 31\n",
      "\t 32\n",
      "\t 33\n",
      "\t 34\n",
      "\t 35\n",
      "\t 36\n",
      "\t 37\n",
      "\t 38\n",
      "\t 39\n",
      "\t 40\n",
      "\t 41\n",
      "\t 42\n",
      "\t 43\n",
      "\t 44\n",
      "\t 45\n",
      "\t 46\n",
      "\t 47\n",
      "\t 48\n",
      "\t 49\n",
      "\t 50\n",
      "\t 51\n",
      "\t 52\n",
      "\t 53\n",
      "\t 54\n",
      "\t 55\n",
      "\t 56\n",
      "\t 57\n",
      "\t 58\n",
      "\t 59\n",
      "\t 60\n",
      "\t 61\n",
      "\t 62\n",
      "\t 63\n",
      "\t 64\n",
      "\t 65\n",
      "\t 66\n",
      "\t 67\n",
      "\t 68\n",
      "\t 69\n",
      "\t 70\n",
      "\t 71\n",
      "\t 72\n",
      "\t 73\n",
      "\t 74\n",
      "\t 75\n",
      "\t 76\n",
      "\t 77\n",
      "7\n",
      "\t 8\n",
      "\t 9\n",
      "\t 10\n",
      "\t 11\n",
      "\t 12\n",
      "\t 13\n",
      "\t 14\n",
      "\t 15\n",
      "\t 16\n",
      "\t 17\n",
      "\t 18\n",
      "\t 19\n",
      "\t 20\n",
      "\t 21\n",
      "\t 22\n",
      "\t 23\n",
      "\t 24\n",
      "\t 25\n",
      "\t 26\n",
      "\t 27\n",
      "\t 28\n",
      "\t 29\n",
      "\t 30\n",
      "\t 31\n",
      "\t 32\n",
      "\t 33\n",
      "\t 34\n",
      "\t 35\n",
      "\t 36\n",
      "\t 37\n",
      "\t 38\n",
      "\t 39\n",
      "\t 40\n",
      "\t 41\n",
      "\t 42\n",
      "\t 43\n",
      "\t 44\n",
      "\t 45\n",
      "\t 46\n",
      "\t 47\n",
      "\t 48\n",
      "\t 49\n",
      "\t 50\n",
      "\t 51\n",
      "\t 52\n",
      "\t 53\n",
      "\t 54\n",
      "\t 55\n",
      "\t 56\n",
      "\t 57\n",
      "\t 58\n",
      "\t 59\n",
      "\t 60\n",
      "\t 61\n",
      "\t 62\n",
      "\t 63\n",
      "\t 64\n",
      "\t 65\n",
      "\t 66\n",
      "\t 67\n",
      "\t 68\n",
      "\t 69\n",
      "\t 70\n",
      "\t 71\n",
      "\t 72\n",
      "\t 73\n",
      "\t 74\n",
      "\t 75\n",
      "\t 76\n",
      "\t 77\n",
      "8\n",
      "\t 9\n",
      "\t 10\n",
      "\t 11\n",
      "\t 12\n",
      "\t 13\n",
      "\t 14\n",
      "\t 15\n",
      "\t 16\n",
      "\t 17\n",
      "\t 18\n",
      "\t 19\n",
      "\t 20\n",
      "\t 21\n",
      "\t 22\n",
      "\t 23\n",
      "\t 24\n",
      "\t 25\n",
      "\t 26\n",
      "\t 27\n",
      "\t 28\n",
      "\t 29\n",
      "\t 30\n",
      "\t 31\n",
      "\t 32\n",
      "\t 33\n",
      "\t 34\n",
      "\t 35\n",
      "\t 36\n",
      "\t 37\n",
      "\t 38\n",
      "\t 39\n",
      "\t 40\n",
      "\t 41\n",
      "\t 42\n",
      "\t 43\n",
      "\t 44\n",
      "\t 45\n",
      "\t 46\n",
      "\t 47\n",
      "\t 48\n",
      "\t 49\n",
      "\t 50\n",
      "\t 51\n",
      "\t 52\n",
      "\t 53\n",
      "\t 54\n",
      "\t 55\n",
      "\t 56\n",
      "\t 57\n",
      "\t 58\n",
      "\t 59\n",
      "\t 60\n",
      "\t 61\n",
      "\t 62\n",
      "\t 63\n",
      "\t 64\n",
      "\t 65\n",
      "\t 66\n",
      "\t 67\n",
      "\t 68\n",
      "\t 69\n",
      "\t 70\n",
      "\t 71\n",
      "\t 72\n",
      "\t 73\n",
      "\t 74\n",
      "\t 75\n",
      "\t 76\n",
      "\t 77\n",
      "9\n",
      "\t 10\n",
      "\t 11\n",
      "\t 12\n",
      "\t 13\n",
      "\t 14\n",
      "\t 15\n",
      "\t 16\n",
      "\t 17\n",
      "\t 18\n",
      "\t 19\n",
      "\t 20\n",
      "\t 21\n",
      "\t 22\n",
      "\t 23\n",
      "\t 24\n",
      "\t 25\n",
      "\t 26\n",
      "\t 27\n",
      "\t 28\n",
      "\t 29\n",
      "\t 30\n",
      "\t 31\n",
      "\t 32\n",
      "\t 33\n",
      "\t 34\n",
      "\t 35\n",
      "\t 36\n",
      "\t 37\n",
      "\t 38\n",
      "\t 39\n",
      "\t 40\n",
      "\t 41\n",
      "\t 42\n",
      "\t 43\n",
      "\t 44\n",
      "\t 45\n",
      "\t 46\n",
      "\t 47\n",
      "\t 48\n",
      "\t 49\n",
      "\t 50\n",
      "\t 51\n",
      "\t 52\n",
      "\t 53\n",
      "\t 54\n",
      "\t 55\n",
      "\t 56\n",
      "\t 57\n",
      "\t 58\n",
      "\t 59\n",
      "\t 60\n",
      "\t 61\n",
      "\t 62\n",
      "\t 63\n",
      "\t 64\n",
      "\t 65\n",
      "\t 66\n",
      "\t 67\n",
      "\t 68\n",
      "\t 69\n",
      "\t 70\n",
      "\t 71\n",
      "\t 72\n",
      "\t 73\n",
      "\t 74\n",
      "\t 75\n",
      "\t 76\n",
      "\t 77\n",
      "10\n",
      "\t 11\n",
      "\t 12\n",
      "\t 13\n",
      "\t 14\n",
      "\t 15\n",
      "\t 16\n",
      "\t 17\n",
      "\t 18\n",
      "\t 19\n",
      "\t 20\n",
      "\t 21\n",
      "\t 22\n",
      "\t 23\n",
      "\t 24\n",
      "\t 25\n",
      "\t 26\n",
      "\t 27\n",
      "\t 28\n",
      "\t 29\n",
      "\t 30\n",
      "\t 31\n",
      "\t 32\n",
      "\t 33\n",
      "\t 34\n",
      "\t 35\n",
      "\t 36\n",
      "\t 37\n",
      "\t 38\n",
      "\t 39\n",
      "\t 40\n",
      "\t 41\n",
      "\t 42\n",
      "\t 43\n",
      "\t 44\n",
      "\t 45\n",
      "\t 46\n",
      "\t 47\n",
      "\t 48\n",
      "\t 49\n",
      "\t 50\n",
      "\t 51\n",
      "\t 52\n",
      "\t 53\n",
      "\t 54\n",
      "\t 55\n",
      "\t 56\n",
      "\t 57\n",
      "\t 58\n",
      "\t 59\n",
      "\t 60\n",
      "\t 61\n",
      "\t 62\n",
      "\t 63\n",
      "\t 64\n",
      "\t 65\n",
      "\t 66\n",
      "\t 67\n",
      "\t 68\n",
      "\t 69\n",
      "\t 70\n",
      "\t 71\n",
      "\t 72\n",
      "\t 73\n",
      "\t 74\n",
      "\t 75\n",
      "\t 76\n",
      "\t 77\n",
      "11\n",
      "\t 12\n",
      "\t 13\n",
      "\t 14\n",
      "\t 15\n",
      "\t 16\n",
      "\t 17\n",
      "\t 18\n",
      "\t 19\n",
      "\t 20\n",
      "\t 21\n",
      "\t 22\n",
      "\t 23\n",
      "\t 24\n",
      "\t 25\n",
      "\t 26\n",
      "\t 27\n",
      "\t 28\n",
      "\t 29\n",
      "\t 30\n",
      "\t 31\n",
      "\t 32\n",
      "\t 33\n",
      "\t 34\n",
      "\t 35\n",
      "\t 36\n",
      "\t 37\n",
      "\t 38\n",
      "\t 39\n",
      "\t 40\n",
      "\t 41\n",
      "\t 42\n",
      "\t 43\n",
      "\t 44\n",
      "\t 45\n",
      "\t 46\n",
      "\t 47\n",
      "\t 48\n",
      "\t 49\n",
      "\t 50\n",
      "\t 51\n",
      "\t 52\n",
      "\t 53\n",
      "\t 54\n",
      "\t 55\n",
      "\t 56\n",
      "\t 57\n",
      "\t 58\n",
      "\t 59\n",
      "\t 60\n",
      "\t 61\n",
      "\t 62\n",
      "\t 63\n",
      "\t 64\n",
      "\t 65\n",
      "\t 66\n",
      "\t 67\n",
      "\t 68\n",
      "\t 69\n",
      "\t 70\n",
      "\t 71\n",
      "\t 72\n",
      "\t 73\n",
      "\t 74\n",
      "\t 75\n",
      "\t 76\n",
      "\t 77\n",
      "12\n",
      "\t 13\n",
      "\t 14\n",
      "\t 15\n",
      "\t 16\n",
      "\t 17\n",
      "\t 18\n",
      "\t 19\n",
      "\t 20\n",
      "\t 21\n",
      "\t 22\n",
      "\t 23\n",
      "\t 24\n",
      "\t 25\n",
      "\t 26\n",
      "\t 27\n",
      "\t 28\n",
      "\t 29\n",
      "\t 30\n",
      "\t 31\n",
      "\t 32\n",
      "\t 33\n",
      "\t 34\n",
      "\t 35\n",
      "\t 36\n",
      "\t 37\n",
      "\t 38\n",
      "\t 39\n",
      "\t 40\n",
      "\t 41\n",
      "\t 42\n",
      "\t 43\n",
      "\t 44\n",
      "\t 45\n",
      "\t 46\n",
      "\t 47\n",
      "\t 48\n",
      "\t 49\n",
      "\t 50\n",
      "\t 51\n",
      "\t 52\n",
      "\t 53\n",
      "\t 54\n",
      "\t 55\n",
      "\t 56\n",
      "\t 57\n",
      "\t 58\n",
      "\t 59\n",
      "\t 60\n",
      "\t 61\n",
      "\t 62\n",
      "\t 63\n",
      "\t 64\n",
      "\t 65\n",
      "\t 66\n",
      "\t 67\n",
      "\t 68\n",
      "\t 69\n",
      "\t 70\n",
      "\t 71\n",
      "\t 72\n",
      "\t 73\n",
      "\t 74\n",
      "\t 75\n",
      "\t 76\n",
      "\t 77\n",
      "13\n",
      "\t 14\n",
      "\t 15\n",
      "\t 16\n",
      "\t 17\n",
      "\t 18\n",
      "\t 19\n",
      "\t 20\n",
      "\t 21\n",
      "\t 22\n",
      "\t 23\n",
      "\t 24\n",
      "\t 25\n",
      "\t 26\n",
      "\t 27\n",
      "\t 28\n",
      "\t 29\n",
      "\t 30\n",
      "\t 31\n",
      "\t 32\n",
      "\t 33\n",
      "\t 34\n",
      "\t 35\n",
      "\t 36\n",
      "\t 37\n",
      "\t 38\n",
      "\t 39\n",
      "\t 40\n",
      "\t 41\n",
      "\t 42\n",
      "\t 43\n",
      "\t 44\n",
      "\t 45\n",
      "\t 46\n",
      "\t 47\n",
      "\t 48\n",
      "\t 49\n",
      "\t 50\n",
      "\t 51\n",
      "\t 52\n",
      "\t 53\n",
      "\t 54\n",
      "\t 55\n",
      "\t 56\n",
      "\t 57\n",
      "\t 58\n",
      "\t 59\n",
      "\t 60\n",
      "\t 61\n",
      "\t 62\n",
      "\t 63\n",
      "\t 64\n",
      "\t 65\n",
      "\t 66\n",
      "\t 67\n",
      "\t 68\n",
      "\t 69\n",
      "\t 70\n",
      "\t 71\n",
      "\t 72\n",
      "\t 73\n",
      "\t 74\n",
      "\t 75\n",
      "\t 76\n",
      "\t 77\n",
      "14\n",
      "\t 15\n",
      "\t 16\n",
      "\t 17\n",
      "\t 18\n",
      "\t 19\n",
      "\t 20\n",
      "\t 21\n",
      "\t 22\n",
      "\t 23\n",
      "\t 24\n",
      "\t 25\n",
      "\t 26\n",
      "\t 27\n",
      "\t 28\n",
      "\t 29\n",
      "\t 30\n",
      "\t 31\n",
      "\t 32\n",
      "\t 33\n",
      "\t 34\n",
      "\t 35\n",
      "\t 36\n",
      "\t 37\n",
      "\t 38\n",
      "\t 39\n",
      "\t 40\n",
      "\t 41\n",
      "\t 42\n",
      "\t 43\n",
      "\t 44\n",
      "\t 45\n",
      "\t 46\n",
      "\t 47\n",
      "\t 48\n",
      "\t 49\n",
      "\t 50\n",
      "\t 51\n",
      "\t 52\n",
      "\t 53\n",
      "\t 54\n",
      "\t 55\n",
      "\t 56\n",
      "\t 57\n",
      "\t 58\n",
      "\t 59\n",
      "\t 60\n",
      "\t 61\n",
      "\t 62\n",
      "\t 63\n",
      "\t 64\n",
      "\t 65\n",
      "\t 66\n",
      "\t 67\n",
      "\t 68\n",
      "\t 69\n",
      "\t 70\n",
      "\t 71\n",
      "\t 72\n",
      "\t 73\n",
      "\t 74\n",
      "\t 75\n",
      "\t 76\n",
      "\t 77\n",
      "15\n",
      "\t 16\n",
      "\t 17\n",
      "\t 18\n",
      "\t 19\n",
      "\t 20\n",
      "\t 21\n",
      "\t 22\n",
      "\t 23\n",
      "\t 24\n",
      "\t 25\n",
      "\t 26\n",
      "\t 27\n",
      "\t 28\n",
      "\t 29\n",
      "\t 30\n",
      "\t 31\n",
      "\t 32\n",
      "\t 33\n",
      "\t 34\n",
      "\t 35\n",
      "\t 36\n",
      "\t 37\n",
      "\t 38\n",
      "\t 39\n",
      "\t 40\n",
      "\t 41\n",
      "\t 42\n",
      "\t 43\n",
      "\t 44\n",
      "\t 45\n",
      "\t 46\n",
      "\t 47\n",
      "\t 48\n",
      "\t 49\n",
      "\t 50\n",
      "\t 51\n",
      "\t 52\n",
      "\t 53\n",
      "\t 54\n",
      "\t 55\n",
      "\t 56\n",
      "\t 57\n",
      "\t 58\n",
      "\t 59\n",
      "\t 60\n",
      "\t 61\n",
      "\t 62\n",
      "\t 63\n",
      "\t 64\n",
      "\t 65\n",
      "\t 66\n",
      "\t 67\n",
      "\t 68\n",
      "\t 69\n",
      "\t 70\n",
      "\t 71\n",
      "\t 72\n",
      "\t 73\n",
      "\t 74\n",
      "\t 75\n",
      "\t 76\n",
      "\t 77\n",
      "16\n",
      "\t 17\n",
      "\t 18\n",
      "\t 19\n",
      "\t 20\n",
      "\t 21\n",
      "\t 22\n",
      "\t 23\n",
      "\t 24\n",
      "\t 25\n",
      "\t 26\n",
      "\t 27\n",
      "\t 28\n",
      "\t 29\n",
      "\t 30\n",
      "\t 31\n",
      "\t 32\n",
      "\t 33\n",
      "\t 34\n",
      "\t 35\n",
      "\t 36\n",
      "\t 37\n",
      "\t 38\n",
      "\t 39\n",
      "\t 40\n",
      "\t 41\n",
      "\t 42\n",
      "\t 43\n",
      "\t 44\n",
      "\t 45\n",
      "\t 46\n",
      "\t 47\n",
      "\t 48\n",
      "\t 49\n",
      "\t 50\n",
      "\t 51\n",
      "\t 52\n",
      "\t 53\n",
      "\t 54\n",
      "\t 55\n",
      "\t 56\n",
      "\t 57\n",
      "\t 58\n",
      "\t 59\n",
      "\t 60\n",
      "\t 61\n",
      "\t 62\n",
      "\t 63\n",
      "\t 64\n",
      "\t 65\n",
      "\t 66\n",
      "\t 67\n",
      "\t 68\n",
      "\t 69\n",
      "\t 70\n",
      "\t 71\n",
      "\t 72\n",
      "\t 73\n",
      "\t 74\n",
      "\t 75\n",
      "\t 76\n",
      "\t 77\n",
      "17\n",
      "\t 18\n",
      "\t 19\n",
      "\t 20\n",
      "\t 21\n",
      "\t 22\n",
      "\t 23\n",
      "\t 24\n",
      "\t 25\n",
      "\t 26\n",
      "\t 27\n",
      "\t 28\n",
      "\t 29\n",
      "\t 30\n",
      "\t 31\n",
      "\t 32\n",
      "\t 33\n",
      "\t 34\n",
      "\t 35\n",
      "\t 36\n",
      "\t 37\n",
      "\t 38\n",
      "\t 39\n",
      "\t 40\n",
      "\t 41\n",
      "\t 42\n",
      "\t 43\n",
      "\t 44\n",
      "\t 45\n",
      "\t 46\n",
      "\t 47\n",
      "\t 48\n",
      "\t 49\n",
      "\t 50\n",
      "\t 51\n",
      "\t 52\n",
      "\t 53\n",
      "\t 54\n",
      "\t 55\n",
      "\t 56\n",
      "\t 57\n",
      "\t 58\n",
      "\t 59\n",
      "\t 60\n",
      "\t 61\n",
      "\t 62\n",
      "\t 63\n",
      "\t 64\n",
      "\t 65\n",
      "\t 66\n",
      "\t 67\n",
      "\t 68\n",
      "\t 69\n",
      "\t 70\n",
      "\t 71\n",
      "\t 72\n",
      "\t 73\n",
      "\t 74\n",
      "\t 75\n",
      "\t 76\n",
      "\t 77\n",
      "18\n",
      "\t 19\n",
      "\t 20\n",
      "\t 21\n",
      "\t 22\n",
      "\t 23\n",
      "\t 24\n",
      "\t 25\n",
      "\t 26\n",
      "\t 27\n",
      "\t 28\n",
      "\t 29\n",
      "\t 30\n",
      "\t 31\n",
      "\t 32\n",
      "\t 33\n",
      "\t 34\n",
      "\t 35\n",
      "\t 36\n",
      "\t 37\n",
      "\t 38\n",
      "\t 39\n",
      "\t 40\n",
      "\t 41\n",
      "\t 42\n",
      "\t 43\n",
      "\t 44\n",
      "\t 45\n",
      "\t 46\n",
      "\t 47\n",
      "\t 48\n",
      "\t 49\n",
      "\t 50\n",
      "\t 51\n",
      "\t 52\n",
      "\t 53\n",
      "\t 54\n",
      "\t 55\n",
      "\t 56\n",
      "\t 57\n",
      "\t 58\n",
      "\t 59\n",
      "\t 60\n",
      "\t 61\n",
      "\t 62\n",
      "\t 63\n",
      "\t 64\n",
      "\t 65\n",
      "\t 66\n",
      "\t 67\n",
      "\t 68\n",
      "\t 69\n",
      "\t 70\n",
      "\t 71\n",
      "\t 72\n",
      "\t 73\n",
      "\t 74\n",
      "\t 75\n",
      "\t 76\n",
      "\t 77\n",
      "19\n",
      "\t 20\n",
      "\t 21\n",
      "\t 22\n",
      "\t 23\n",
      "\t 24\n",
      "\t 25\n",
      "\t 26\n",
      "\t 27\n",
      "\t 28\n",
      "\t 29\n",
      "\t 30\n",
      "\t 31\n",
      "\t 32\n",
      "\t 33\n",
      "\t 34\n",
      "\t 35\n",
      "\t 36\n",
      "\t 37\n",
      "\t 38\n",
      "\t 39\n",
      "\t 40\n",
      "\t 41\n",
      "\t 42\n",
      "\t 43\n",
      "\t 44\n",
      "\t 45\n",
      "\t 46\n",
      "\t 47\n",
      "\t 48\n",
      "\t 49\n",
      "\t 50\n",
      "\t 51\n",
      "\t 52\n",
      "\t 53\n",
      "\t 54\n",
      "\t 55\n",
      "\t 56\n",
      "\t 57\n",
      "\t 58\n",
      "\t 59\n",
      "\t 60\n",
      "\t 61\n",
      "\t 62\n",
      "\t 63\n",
      "\t 64\n",
      "\t 65\n",
      "\t 66\n",
      "\t 67\n",
      "\t 68\n",
      "\t 69\n",
      "\t 70\n",
      "\t 71\n",
      "\t 72\n",
      "\t 73\n",
      "\t 74\n",
      "\t 75\n",
      "\t 76\n",
      "\t 77\n",
      "20\n",
      "\t 21\n",
      "\t 22\n",
      "\t 23\n",
      "\t 24\n",
      "\t 25\n",
      "\t 26\n",
      "\t 27\n",
      "\t 28\n",
      "\t 29\n",
      "\t 30\n",
      "\t 31\n",
      "\t 32\n",
      "\t 33\n",
      "\t 34\n",
      "\t 35\n",
      "\t 36\n",
      "\t 37\n",
      "\t 38\n",
      "\t 39\n",
      "\t 40\n",
      "\t 41\n",
      "\t 42\n",
      "\t 43\n",
      "\t 44\n",
      "\t 45\n",
      "\t 46\n",
      "\t 47\n",
      "\t 48\n",
      "\t 49\n",
      "\t 50\n",
      "\t 51\n",
      "\t 52\n",
      "\t 53\n",
      "\t 54\n",
      "\t 55\n",
      "\t 56\n",
      "\t 57\n",
      "\t 58\n",
      "\t 59\n",
      "\t 60\n",
      "\t 61\n",
      "\t 62\n",
      "\t 63\n",
      "\t 64\n",
      "\t 65\n",
      "\t 66\n",
      "\t 67\n",
      "\t 68\n",
      "\t 69\n",
      "\t 70\n",
      "\t 71\n",
      "\t 72\n",
      "\t 73\n",
      "\t 74\n",
      "\t 75\n",
      "\t 76\n",
      "\t 77\n",
      "21\n",
      "\t 22\n",
      "\t 23\n",
      "\t 24\n",
      "\t 25\n",
      "\t 26\n",
      "\t 27\n",
      "\t 28\n",
      "\t 29\n",
      "\t 30\n",
      "\t 31\n",
      "\t 32\n",
      "\t 33\n",
      "\t 34\n",
      "\t 35\n",
      "\t 36\n",
      "\t 37\n",
      "\t 38\n",
      "\t 39\n",
      "\t 40\n",
      "\t 41\n",
      "\t 42\n",
      "\t 43\n",
      "\t 44\n",
      "\t 45\n",
      "\t 46\n",
      "\t 47\n",
      "\t 48\n",
      "\t 49\n",
      "\t 50\n",
      "\t 51\n",
      "\t 52\n",
      "\t 53\n",
      "\t 54\n",
      "\t 55\n",
      "\t 56\n",
      "\t 57\n",
      "\t 58\n",
      "\t 59\n",
      "\t 60\n",
      "\t 61\n",
      "\t 62\n",
      "\t 63\n",
      "\t 64\n",
      "\t 65\n",
      "\t 66\n",
      "\t 67\n",
      "\t 68\n",
      "\t 69\n",
      "\t 70\n",
      "\t 71\n",
      "\t 72\n",
      "\t 73\n",
      "\t 74\n",
      "\t 75\n",
      "\t 76\n",
      "\t 77\n",
      "22\n",
      "\t 23\n",
      "\t 24\n",
      "\t 25\n",
      "\t 26\n",
      "\t 27\n",
      "\t 28\n",
      "\t 29\n",
      "\t 30\n",
      "\t 31\n",
      "\t 32\n",
      "\t 33\n",
      "\t 34\n",
      "\t 35\n",
      "\t 36\n",
      "\t 37\n",
      "\t 38\n",
      "\t 39\n",
      "\t 40\n",
      "\t 41\n",
      "\t 42\n",
      "\t 43\n",
      "\t 44\n",
      "\t 45\n",
      "\t 46\n",
      "\t 47\n",
      "\t 48\n",
      "\t 49\n",
      "\t 50\n",
      "\t 51\n",
      "\t 52\n",
      "\t 53\n",
      "\t 54\n",
      "\t 55\n",
      "\t 56\n",
      "\t 57\n",
      "\t 58\n",
      "\t 59\n",
      "\t 60\n",
      "\t 61\n",
      "\t 62\n",
      "\t 63\n",
      "\t 64\n",
      "\t 65\n",
      "\t 66\n",
      "\t 67\n",
      "\t 68\n",
      "\t 69\n",
      "\t 70\n",
      "\t 71\n",
      "\t 72\n",
      "\t 73\n",
      "\t 74\n",
      "\t 75\n",
      "\t 76\n",
      "\t 77\n",
      "23\n",
      "\t 24\n",
      "\t 25\n",
      "\t 26\n",
      "\t 27\n",
      "\t 28\n",
      "\t 29\n",
      "\t 30\n",
      "\t 31\n",
      "\t 32\n",
      "\t 33\n",
      "\t 34\n",
      "\t 35\n",
      "\t 36\n",
      "\t 37\n",
      "\t 38\n",
      "\t 39\n",
      "\t 40\n",
      "\t 41\n",
      "\t 42\n",
      "\t 43\n",
      "\t 44\n",
      "\t 45\n",
      "\t 46\n",
      "\t 47\n",
      "\t 48\n",
      "\t 49\n",
      "\t 50\n",
      "\t 51\n",
      "\t 52\n",
      "\t 53\n",
      "\t 54\n",
      "\t 55\n",
      "\t 56\n",
      "\t 57\n",
      "\t 58\n",
      "\t 59\n",
      "\t 60\n",
      "\t 61\n",
      "\t 62\n",
      "\t 63\n",
      "\t 64\n",
      "\t 65\n",
      "\t 66\n",
      "\t 67\n",
      "\t 68\n",
      "\t 69\n",
      "\t 70\n",
      "\t 71\n",
      "\t 72\n",
      "\t 73\n",
      "\t 74\n",
      "\t 75\n",
      "\t 76\n",
      "\t 77\n",
      "24\n",
      "\t 25\n",
      "\t 26\n",
      "\t 27\n",
      "\t 28\n",
      "\t 29\n",
      "\t 30\n",
      "\t 31\n",
      "\t 32\n",
      "\t 33\n",
      "\t 34\n",
      "\t 35\n",
      "\t 36\n",
      "\t 37\n",
      "\t 38\n",
      "\t 39\n",
      "\t 40\n",
      "\t 41\n",
      "\t 42\n",
      "\t 43\n",
      "\t 44\n",
      "\t 45\n",
      "\t 46\n",
      "\t 47\n",
      "\t 48\n",
      "\t 49\n",
      "\t 50\n",
      "\t 51\n",
      "\t 52\n",
      "\t 53\n",
      "\t 54\n",
      "\t 55\n",
      "\t 56\n",
      "\t 57\n",
      "\t 58\n",
      "\t 59\n",
      "\t 60\n",
      "\t 61\n",
      "\t 62\n",
      "\t 63\n",
      "\t 64\n",
      "\t 65\n",
      "\t 66\n",
      "\t 67\n",
      "\t 68\n",
      "\t 69\n",
      "\t 70\n",
      "\t 71\n",
      "\t 72\n",
      "\t 73\n",
      "\t 74\n",
      "\t 75\n",
      "\t 76\n",
      "\t 77\n",
      "25\n",
      "\t 26\n",
      "\t 27\n",
      "\t 28\n",
      "\t 29\n",
      "\t 30\n",
      "\t 31\n",
      "\t 32\n",
      "\t 33\n",
      "\t 34\n",
      "\t 35\n",
      "\t 36\n",
      "\t 37\n",
      "\t 38\n",
      "\t 39\n",
      "\t 40\n",
      "\t 41\n",
      "\t 42\n",
      "\t 43\n",
      "\t 44\n",
      "\t 45\n",
      "\t 46\n",
      "\t 47\n",
      "\t 48\n",
      "\t 49\n",
      "\t 50\n",
      "\t 51\n",
      "\t 52\n",
      "\t 53\n",
      "\t 54\n",
      "\t 55\n",
      "\t 56\n",
      "\t 57\n",
      "\t 58\n",
      "\t 59\n",
      "\t 60\n",
      "\t 61\n",
      "\t 62\n",
      "\t 63\n",
      "\t 64\n",
      "\t 65\n",
      "\t 66\n",
      "\t 67\n",
      "\t 68\n",
      "\t 69\n",
      "\t 70\n",
      "\t 71\n",
      "\t 72\n",
      "\t 73\n",
      "\t 74\n",
      "\t 75\n",
      "\t 76\n",
      "\t 77\n",
      "26\n",
      "\t 27\n",
      "\t 28\n",
      "\t 29\n",
      "\t 30\n",
      "\t 31\n",
      "\t 32\n",
      "\t 33\n",
      "\t 34\n",
      "\t 35\n",
      "\t 36\n",
      "\t 37\n",
      "\t 38\n",
      "\t 39\n",
      "\t 40\n",
      "\t 41\n",
      "\t 42\n",
      "\t 43\n",
      "\t 44\n",
      "\t 45\n",
      "\t 46\n",
      "\t 47\n",
      "\t 48\n",
      "\t 49\n",
      "\t 50\n",
      "\t 51\n",
      "\t 52\n",
      "\t 53\n",
      "\t 54\n",
      "\t 55\n",
      "\t 56\n",
      "\t 57\n",
      "\t 58\n",
      "\t 59\n",
      "\t 60\n",
      "\t 61\n",
      "\t 62\n",
      "\t 63\n",
      "\t 64\n",
      "\t 65\n",
      "\t 66\n",
      "\t 67\n",
      "\t 68\n",
      "\t 69\n",
      "\t 70\n",
      "\t 71\n",
      "\t 72\n",
      "\t 73\n",
      "\t 74\n",
      "\t 75\n",
      "\t 76\n",
      "\t 77\n",
      "27\n",
      "\t 28\n",
      "\t 29\n",
      "\t 30\n",
      "\t 31\n",
      "\t 32\n",
      "\t 33\n",
      "\t 34\n",
      "\t 35\n",
      "\t 36\n",
      "\t 37\n",
      "\t 38\n",
      "\t 39\n",
      "\t 40\n",
      "\t 41\n",
      "\t 42\n",
      "\t 43\n",
      "\t 44\n",
      "\t 45\n",
      "\t 46\n",
      "\t 47\n",
      "\t 48\n",
      "\t 49\n",
      "\t 50\n",
      "\t 51\n",
      "\t 52\n",
      "\t 53\n",
      "\t 54\n",
      "\t 55\n",
      "\t 56\n",
      "\t 57\n",
      "\t 58\n",
      "\t 59\n",
      "\t 60\n",
      "\t 61\n",
      "\t 62\n",
      "\t 63\n",
      "\t 64\n",
      "\t 65\n",
      "\t 66\n",
      "\t 67\n",
      "\t 68\n",
      "\t 69\n",
      "\t 70\n",
      "\t 71\n",
      "\t 72\n",
      "\t 73\n",
      "\t 74\n",
      "\t 75\n",
      "\t 76\n",
      "\t 77\n",
      "28\n",
      "\t 29\n",
      "\t 30\n",
      "\t 31\n",
      "\t 32\n",
      "\t 33\n",
      "\t 34\n",
      "\t 35\n",
      "\t 36\n",
      "\t 37\n",
      "\t 38\n",
      "\t 39\n",
      "\t 40\n",
      "\t 41\n",
      "\t 42\n",
      "\t 43\n",
      "\t 44\n",
      "\t 45\n",
      "\t 46\n",
      "\t 47\n",
      "\t 48\n",
      "\t 49\n",
      "\t 50\n",
      "\t 51\n",
      "\t 52\n",
      "\t 53\n",
      "\t 54\n",
      "\t 55\n",
      "\t 56\n",
      "\t 57\n",
      "\t 58\n",
      "\t 59\n",
      "\t 60\n",
      "\t 61\n",
      "\t 62\n",
      "\t 63\n",
      "\t 64\n",
      "\t 65\n",
      "\t 66\n",
      "\t 67\n",
      "\t 68\n",
      "\t 69\n",
      "\t 70\n",
      "\t 71\n",
      "\t 72\n",
      "\t 73\n",
      "\t 74\n",
      "\t 75\n",
      "\t 76\n",
      "\t 77\n",
      "29\n",
      "\t 30\n",
      "\t 31\n",
      "\t 32\n",
      "\t 33\n",
      "\t 34\n",
      "\t 35\n",
      "\t 36\n",
      "\t 37\n",
      "\t 38\n",
      "\t 39\n",
      "\t 40\n",
      "\t 41\n",
      "\t 42\n",
      "\t 43\n",
      "\t 44\n",
      "\t 45\n",
      "\t 46\n",
      "\t 47\n",
      "\t 48\n",
      "\t 49\n",
      "\t 50\n",
      "\t 51\n",
      "\t 52\n",
      "\t 53\n",
      "\t 54\n",
      "\t 55\n",
      "\t 56\n",
      "\t 57\n",
      "\t 58\n",
      "\t 59\n",
      "\t 60\n",
      "\t 61\n",
      "\t 62\n",
      "\t 63\n",
      "\t 64\n",
      "\t 65\n",
      "\t 66\n",
      "\t 67\n",
      "\t 68\n",
      "\t 69\n",
      "\t 70\n",
      "\t 71\n",
      "\t 72\n",
      "\t 73\n",
      "\t 74\n",
      "\t 75\n",
      "\t 76\n",
      "\t 77\n",
      "30\n",
      "\t 31\n",
      "\t 32\n",
      "\t 33\n",
      "\t 34\n",
      "\t 35\n",
      "\t 36\n",
      "\t 37\n",
      "\t 38\n",
      "\t 39\n",
      "\t 40\n",
      "\t 41\n",
      "\t 42\n",
      "\t 43\n",
      "\t 44\n",
      "\t 45\n",
      "\t 46\n",
      "\t 47\n",
      "\t 48\n",
      "\t 49\n",
      "\t 50\n",
      "\t 51\n",
      "\t 52\n",
      "\t 53\n",
      "\t 54\n",
      "\t 55\n",
      "\t 56\n",
      "\t 57\n",
      "\t 58\n",
      "\t 59\n",
      "\t 60\n",
      "\t 61\n",
      "\t 62\n",
      "\t 63\n",
      "\t 64\n",
      "\t 65\n",
      "\t 66\n",
      "\t 67\n",
      "\t 68\n",
      "\t 69\n",
      "\t 70\n",
      "\t 71\n",
      "\t 72\n",
      "\t 73\n",
      "\t 74\n",
      "\t 75\n",
      "\t 76\n",
      "\t 77\n",
      "31\n",
      "\t 32\n",
      "\t 33\n",
      "\t 34\n",
      "\t 35\n",
      "\t 36\n",
      "\t 37\n",
      "\t 38\n",
      "\t 39\n",
      "\t 40\n",
      "\t 41\n",
      "\t 42\n",
      "\t 43\n",
      "\t 44\n",
      "\t 45\n",
      "\t 46\n",
      "\t 47\n",
      "\t 48\n",
      "\t 49\n",
      "\t 50\n",
      "\t 51\n",
      "\t 52\n",
      "\t 53\n",
      "\t 54\n",
      "\t 55\n",
      "\t 56\n",
      "\t 57\n",
      "\t 58\n",
      "\t 59\n",
      "\t 60\n",
      "\t 61\n",
      "\t 62\n",
      "\t 63\n",
      "\t 64\n",
      "\t 65\n",
      "\t 66\n",
      "\t 67\n",
      "\t 68\n",
      "\t 69\n",
      "\t 70\n",
      "\t 71\n",
      "\t 72\n",
      "\t 73\n",
      "\t 74\n",
      "\t 75\n",
      "\t 76\n",
      "\t 77\n",
      "32\n",
      "\t 33\n",
      "\t 34\n",
      "\t 35\n",
      "\t 36\n",
      "\t 37\n",
      "\t 38\n",
      "\t 39\n",
      "\t 40\n",
      "\t 41\n",
      "\t 42\n",
      "\t 43\n",
      "\t 44\n",
      "\t 45\n",
      "\t 46\n",
      "\t 47\n",
      "\t 48\n",
      "\t 49\n",
      "\t 50\n",
      "\t 51\n",
      "\t 52\n",
      "\t 53\n",
      "\t 54\n",
      "\t 55\n",
      "\t 56\n",
      "\t 57\n",
      "\t 58\n",
      "\t 59\n",
      "\t 60\n",
      "\t 61\n",
      "\t 62\n",
      "\t 63\n",
      "\t 64\n",
      "\t 65\n",
      "\t 66\n",
      "\t 67\n",
      "\t 68\n",
      "\t 69\n",
      "\t 70\n",
      "\t 71\n",
      "\t 72\n",
      "\t 73\n",
      "\t 74\n",
      "\t 75\n",
      "\t 76\n",
      "\t 77\n",
      "33\n",
      "\t 34\n",
      "\t 35\n",
      "\t 36\n",
      "\t 37\n",
      "\t 38\n",
      "\t 39\n",
      "\t 40\n",
      "\t 41\n",
      "\t 42\n",
      "\t 43\n",
      "\t 44\n",
      "\t 45\n",
      "\t 46\n",
      "\t 47\n",
      "\t 48\n",
      "\t 49\n",
      "\t 50\n",
      "\t 51\n",
      "\t 52\n",
      "\t 53\n",
      "\t 54\n",
      "\t 55\n",
      "\t 56\n",
      "\t 57\n",
      "\t 58\n",
      "\t 59\n",
      "\t 60\n",
      "\t 61\n",
      "\t 62\n",
      "\t 63\n",
      "\t 64\n",
      "\t 65\n",
      "\t 66\n",
      "\t 67\n",
      "\t 68\n",
      "\t 69\n",
      "\t 70\n",
      "\t 71\n",
      "\t 72\n",
      "\t 73\n",
      "\t 74\n",
      "\t 75\n",
      "\t 76\n",
      "\t 77\n",
      "34\n",
      "\t 35\n",
      "\t 36\n",
      "\t 37\n",
      "\t 38\n",
      "\t 39\n",
      "\t 40\n",
      "\t 41\n",
      "\t 42\n",
      "\t 43\n",
      "\t 44\n",
      "\t 45\n",
      "\t 46\n",
      "\t 47\n",
      "\t 48\n",
      "\t 49\n",
      "\t 50\n",
      "\t 51\n",
      "\t 52\n",
      "\t 53\n",
      "\t 54\n",
      "\t 55\n",
      "\t 56\n",
      "\t 57\n",
      "\t 58\n",
      "\t 59\n",
      "\t 60\n",
      "\t 61\n",
      "\t 62\n",
      "\t 63\n",
      "\t 64\n",
      "\t 65\n",
      "\t 66\n",
      "\t 67\n",
      "\t 68\n",
      "\t 69\n",
      "\t 70\n",
      "\t 71\n",
      "\t 72\n",
      "\t 73\n",
      "\t 74\n",
      "\t 75\n",
      "\t 76\n",
      "\t 77\n",
      "35\n",
      "\t 36\n",
      "\t 37\n",
      "\t 38\n",
      "\t 39\n",
      "\t 40\n",
      "\t 41\n",
      "\t 42\n",
      "\t 43\n",
      "\t 44\n",
      "\t 45\n",
      "\t 46\n",
      "\t 47\n",
      "\t 48\n",
      "\t 49\n",
      "\t 50\n",
      "\t 51\n",
      "\t 52\n",
      "\t 53\n",
      "\t 54\n",
      "\t 55\n",
      "\t 56\n",
      "\t 57\n",
      "\t 58\n",
      "\t 59\n",
      "\t 60\n",
      "\t 61\n",
      "\t 62\n",
      "\t 63\n",
      "\t 64\n",
      "\t 65\n",
      "\t 66\n",
      "\t 67\n",
      "\t 68\n",
      "\t 69\n",
      "\t 70\n",
      "\t 71\n",
      "\t 72\n",
      "\t 73\n",
      "\t 74\n",
      "\t 75\n",
      "\t 76\n",
      "\t 77\n",
      "36\n",
      "\t 37\n",
      "\t 38\n",
      "\t 39\n",
      "\t 40\n",
      "\t 41\n",
      "\t 42\n",
      "\t 43\n",
      "\t 44\n",
      "\t 45\n",
      "\t 46\n",
      "\t 47\n",
      "\t 48\n",
      "\t 49\n",
      "\t 50\n",
      "\t 51\n",
      "\t 52\n",
      "\t 53\n",
      "\t 54\n",
      "\t 55\n",
      "\t 56\n",
      "\t 57\n",
      "\t 58\n",
      "\t 59\n",
      "\t 60\n",
      "\t 61\n",
      "\t 62\n",
      "\t 63\n",
      "\t 64\n",
      "\t 65\n",
      "\t 66\n",
      "\t 67\n",
      "\t 68\n",
      "\t 69\n",
      "\t 70\n",
      "\t 71\n",
      "\t 72\n",
      "\t 73\n",
      "\t 74\n",
      "\t 75\n",
      "\t 76\n",
      "\t 77\n",
      "37\n",
      "\t 38\n",
      "\t 39\n",
      "\t 40\n",
      "\t 41\n",
      "\t 42\n",
      "\t 43\n",
      "\t 44\n",
      "\t 45\n",
      "\t 46\n",
      "\t 47\n",
      "\t 48\n",
      "\t 49\n",
      "\t 50\n",
      "\t 51\n",
      "\t 52\n",
      "\t 53\n",
      "\t 54\n",
      "\t 55\n",
      "\t 56\n",
      "\t 57\n",
      "\t 58\n",
      "\t 59\n",
      "\t 60\n",
      "\t 61\n",
      "\t 62\n",
      "\t 63\n",
      "\t 64\n",
      "\t 65\n",
      "\t 66\n",
      "\t 67\n",
      "\t 68\n",
      "\t 69\n",
      "\t 70\n",
      "\t 71\n",
      "\t 72\n",
      "\t 73\n",
      "\t 74\n",
      "\t 75\n",
      "\t 76\n",
      "\t 77\n",
      "38\n",
      "\t 39\n",
      "\t 40\n",
      "\t 41\n",
      "\t 42\n",
      "\t 43\n",
      "\t 44\n",
      "\t 45\n",
      "\t 46\n",
      "\t 47\n",
      "\t 48\n",
      "\t 49\n",
      "\t 50\n",
      "\t 51\n",
      "\t 52\n",
      "\t 53\n",
      "\t 54\n",
      "\t 55\n",
      "\t 56\n",
      "\t 57\n",
      "\t 58\n",
      "\t 59\n",
      "\t 60\n",
      "\t 61\n",
      "\t 62\n",
      "\t 63\n",
      "\t 64\n",
      "\t 65\n",
      "\t 66\n",
      "\t 67\n",
      "\t 68\n",
      "\t 69\n",
      "\t 70\n",
      "\t 71\n",
      "\t 72\n",
      "\t 73\n",
      "\t 74\n",
      "\t 75\n",
      "\t 76\n",
      "\t 77\n",
      "39\n",
      "\t 40\n",
      "\t 41\n",
      "\t 42\n",
      "\t 43\n",
      "\t 44\n",
      "\t 45\n",
      "\t 46\n",
      "\t 47\n",
      "\t 48\n",
      "\t 49\n",
      "\t 50\n",
      "\t 51\n",
      "\t 52\n",
      "\t 53\n",
      "\t 54\n",
      "\t 55\n",
      "\t 56\n",
      "\t 57\n",
      "\t 58\n",
      "\t 59\n",
      "\t 60\n",
      "\t 61\n",
      "\t 62\n",
      "\t 63\n",
      "\t 64\n",
      "\t 65\n",
      "\t 66\n",
      "\t 67\n",
      "\t 68\n",
      "\t 69\n",
      "\t 70\n",
      "\t 71\n",
      "\t 72\n",
      "\t 73\n",
      "\t 74\n",
      "\t 75\n",
      "\t 76\n",
      "\t 77\n",
      "40\n",
      "\t 41\n",
      "\t 42\n",
      "\t 43\n",
      "\t 44\n",
      "\t 45\n",
      "\t 46\n",
      "\t 47\n",
      "\t 48\n",
      "\t 49\n",
      "\t 50\n",
      "\t 51\n",
      "\t 52\n",
      "\t 53\n",
      "\t 54\n",
      "\t 55\n",
      "\t 56\n",
      "\t 57\n",
      "\t 58\n",
      "\t 59\n",
      "\t 60\n",
      "\t 61\n",
      "\t 62\n",
      "\t 63\n",
      "\t 64\n",
      "\t 65\n",
      "\t 66\n",
      "\t 67\n",
      "\t 68\n",
      "\t 69\n",
      "\t 70\n",
      "\t 71\n",
      "\t 72\n",
      "\t 73\n",
      "\t 74\n",
      "\t 75\n",
      "\t 76\n",
      "\t 77\n",
      "41\n",
      "\t 42\n",
      "\t 43\n",
      "\t 44\n",
      "\t 45\n",
      "\t 46\n",
      "\t 47\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "for feature_A in tempDF.columns:\n",
    "    newA = True\n",
    "    for feature_B in tempDF.columns:\n",
    "        isInteractionColumn = feature_A == \"interaction\" or feature_B == \"interaction\" \n",
    "        if not isInteractionColumn and int(feature_A) < int(feature_B):\n",
    "            if newA:\n",
    "                print(feature_A, flush=True)\n",
    "                newA = False\n",
    "            print(\"\\t\",feature_B, flush=True)\n",
    "            tempDF['interaction'] = tempDF[feature_A] * tempDF[feature_B]\n",
    "            logitModel.fit(tempDF, y)\n",
    "            score = logitModel.score(tempDF,y)\n",
    "            if score > baseline:\n",
    "                interactions.append((feature_A, feature_B, round(score,8)))\n",
    "t1 = time()\n",
    "print('Baseline R2: %.3f' % baseline)\n",
    "print('Top 10 interactions: %s' % sorted(interactions ,key = lambda x:x[2], reverse=True)[:10])\n",
    "print(\"Time to gather all interactions and determine the best\", t1 - t0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Logistic Regression with top three interaction terms added on\\n\",\n",
    "interactionDF = df1.copy()\n",
    "interactionDF[\"Interaction_One\"] = interactionDF[64] * interactionDF[65]\n",
    "interactionDF[\"Interaction_Two\"] = interactionDF[23] * interactionDF[55]\n",
    "interactionDF[\"Interaction_Three\"] = interactionDF[18] * interactionDF[65]\n",
    "\n",
    "t0 = time()\n",
    "logitModel = LogisticRegression(n_jobs=-1)\n",
    "t1 = time()\n",
    "logitValues = cross_val_score(logitModel, interactionDF, y=y, n_jobs=-1, verbose=1, scoring=\"accuracy\")\n",
    "t2 = time()\n",
    "logitMean = logitValues.mean()\n",
    "print(\"Time to run the model\", t1 - t0)\n",
    "print(\"Time to run 5-Folds\", t2 - t1)\n",
    "print(\"Mean accuracy through 5-folds\", logitMean)\n",
    "\n",
    "interactionDF.drop(columns=[64, 65, 23, 55, 18], inplace=True)\n",
    "t0 = time()\n",
    "logitModel = LogisticRegression(n_jobs=-1)\n",
    "t1 = time()\n",
    "logitValues = cross_val_score(logitModel, interactionDF, y=y, n_jobs=-1, verbose=1, scoring=\"accuracy\")\n",
    "t2 = time()\n",
    "logitMean = logitValues.mean()\n",
    "print(\"Time to run the model\", t1 - t0)\n",
    "print(\"Time to run 5-Folds\", t2 - t1)\n",
    "print(\"Mean accuracy through 5-folds\", logitMean)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------Random Forest----------\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# sorted(sklearn.metrics.SCORERS.keys())\n",
    "\n",
    "# Gini\n",
    "t0 = time()\n",
    "rfGini = RandomForestClassifier(criterion=\"gini\", n_estimators = 100, random_state = 42, n_jobs=-1, verbose=1)\n",
    "t1 = time()\n",
    "dtGiniValues = cross_val_score(rfGini, df1, y=y, n_jobs=-1, verbose=1, scoring=\"accuracy\")\n",
    "t2 = time()\n",
    "dtGiniMean = dtGiniValues.mean()\n",
    "print(\"Time to run the model\", t1 - t0)\n",
    "print(\"Time to run 5-Folds\", t2 - t1)\n",
    "print(\"Mean accuracy through 5-folds\", dtGiniMean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Entropy\n",
    "t0 = time()\n",
    "rfEntropy = RandomForestClassifier(criterion=\"entropy\", n_estimators = 100, random_state = 42, n_jobs=-1, verbose=1)\n",
    "t1 = time()\n",
    "dtEntropyValues = cross_val_score(rfEntropy, df1, y=y, n_jobs=-1, verbose=1, scoring=\"accuracy\")\n",
    "t2 = time()\n",
    "dtEntropyMean = dtEntropyValues.mean()\n",
    "print(\"Time to run the model\", t1 - t0)\n",
    "print(\"Time to run 5-Folds\", t2 - t1)\n",
    "print(\"Mean accuracy through 5-folds\", dtEntropyMean)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Gradient Boosting Classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "t0 = time()\n",
    "gb_clf = GradientBoostingClassifier()\n",
    "t1 = time()\n",
    "gbclfScores = cross_val_score(gb_clf, df1, y=y, n_jobs=-1, verbose=1, scoring=\"accuracy\")\n",
    "t2 = time()\n",
    "gbclfMean = gbclfScores.mean()\n",
    "print(\"Time to run the model\", t1 - t0)\n",
    "print(\"Time to run 5-Folds\", t2 - t1)\n",
    "print(\"Mean accuracy through 5-folds\", gbclfMean)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Comparisons of fitted models using c-statistics, i.e., AUC of the ROC curve\n",
    "\n",
    "# Splitting data into 5 folds in order to use the same data for each ROC\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df1, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# AUC Scores:\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "#-------- Logistic Regression\n",
    "logitModel.fit(X_train, y_train)\n",
    "probs1 = logitModel.predict_proba(X_test)\n",
    "probs1 = probs1[:, 1]\n",
    "auc_logit = roc_auc_score(y_test, probs1)\n",
    "print('Logit AUC: %.2f' % auc_logit)\n",
    "#-------- Gradient Boosting\n",
    "gb_clf.fit(X_train, y_train)\n",
    "probs2 = gb_clf.predict_proba(X_test)\n",
    "probs2 = probs2[:, 1]\n",
    "auc_gbf = roc_auc_score(y_test, probs2)\n",
    "print('GBF AUC: %.2f' % auc_gbf)\n",
    "#-------- Random Forest Gini\n",
    "rfGini.fit(X_train, y_train)\n",
    "probs3 = rfGini.predict_proba(X_test)\n",
    "probs3 = probs3[:, 1]\n",
    "auc_rfGini = roc_auc_score(y_test, probs3)\n",
    "print('RF Gini AUC: %.2f' % auc_rfGini)\n",
    "#-------- Random Forest Entropy\n",
    "rfEntropy.fit(X_train, y_train)\n",
    "probs4 = rfEntropy.predict_proba(X_test)\n",
    "probs4 = probs4[:, 1]\n",
    "auc_rfEntropy = roc_auc_score(y_test, probs4)\n",
    "print('Entropy Gini AUC: %.2f' % auc_rfEntropy)\n",
    "\n",
    "def plot_roc_curve(fpr, tpr):\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probs1)\n",
    "plot_roc_curve(fpr, tpr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, probs2)\n",
    "plot_roc_curve(fpr, tpr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, probs3)\n",
    "plot_roc_curve(fpr, tpr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, probs4)\n",
    "plot_roc_curve(fpr, tpr)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}